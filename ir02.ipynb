{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd03242fe88ee299763c01d0bb81546e51fba598b10f02b9c3d944a8bc4c2f5d633",
   "display_name": "Python 3.8.8 64-bit ('df': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機十篇id\n",
    "# M.1127219109.A.837\n",
    "# M.1127227032.A.F3B\n",
    "# M.1127365129.A.D61\n",
    "# M.1127395683.A.DB9\n",
    "# M.1127526873.A.CD5\n",
    "# M.1127533364.A.C32\n",
    "# M.1127544042.A.E06\n",
    "# M.1127586620.A.EDB\n",
    "# M.1127588070.A.525\n",
    "# M.1127590679.A.006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用比較快快的json parser : ujson\n",
    "try:\n",
    "    import ujson as json\n",
    "except ImportError:\n",
    "    try:\n",
    "        import simplejson as json\n",
    "    except ImportError:\n",
    "        import json\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "# load tfidf\n",
    "\n",
    "def readJson2Data(filename):\n",
    "  f = open(filename, \"r\", encoding='UTF-8')\n",
    "  docText = f.read()\n",
    "  f.close()\n",
    "  return json.loads(docText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 'sample1000_gossiping_dataset_doc_vector.json'\n",
    "ALLDATA = 'gossiping_dataset_doc_vector.json'\n",
    "# data_tfidf = readJson2Data(ALLDATA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DOC_NAME = 'data_user-docIDs.json'\n",
    "name_docid = readJson2Data(DOC_NAME)\n",
    "NLVECTOR = 'name-docID_NLvector.json'\n",
    "docID_name_NLvector = readJson2Data(NLVECTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tools\n",
    "# def saveSmallData(data):\n",
    "#     jsObj = json.dumps(data)\n",
    "    \n",
    "#     fileObject = open('sample1000.json', 'w')\n",
    "#     fileObject.write(jsObj)\n",
    "#     fileObject.close()  \n",
    "# # saveSmallData(sample)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# sample = {}\n",
    "# counter = 0\n",
    "# for k in data_tfidf.keys():\n",
    "#     if counter == 10:\n",
    "#         break\n",
    "#     print(k)\n",
    "#     data_tfidf[k]\n",
    "#     sample[k] = data_tfidf[k]\n",
    "\n",
    "#     counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calNormalizedLength(id):\n",
    "    vector = {}\n",
    "    sum = 0\n",
    "    for word in data_tfidf[id].keys(): \n",
    "        sum = sum + math.pow(data_tfidf[id][word], 2)\n",
    "    \n",
    "    sqrt = math.sqrt(sum)\n",
    "\n",
    "    # 每項除除平方根\n",
    "    for word in data_tfidf[id].keys():\n",
    "        vector[word] = data_tfidf[id][word] / sqrt\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def findCommonWordSet(ida,idb):\n",
    "    CommonWordSet = set()\n",
    "    Aset = set( docID_name_NLvector[ida].keys() )\n",
    "    Bset = set( docID_name_NLvector[idb].keys() )\n",
    "\n",
    "    for token in Aset:\n",
    "        if token in Bset:\n",
    "            CommonWordSet.add(token)\n",
    "    return CommonWordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getNLvector(ida,idb):\n",
    "    return [docID_name_NLvector[ida], docID_name_NLvector[idb]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit\n",
    "def cos(ida,idb):\n",
    "    # get calNormalizedLength\n",
    "    # ida_NL = docID_name_NLvector[ida]\n",
    "    # idb_NL = docID_name_NLvector[idb]\n",
    "    ida_NL, idb_NL = getNLvector(ida,idb)\n",
    "\n",
    "    # findCommonWordSet\n",
    "    commonWordSet = findCommonWordSet(ida,idb)\n",
    "\n",
    "    # v1 = []\n",
    "    # v2 = []\n",
    "    # for word in commonWordSet:\n",
    "    #     v1.append(ida_NL[word])\n",
    "    #     v2.append(idb_NL[word])\n",
    "    \n",
    "    # # use numpy\n",
    "    # v1 = np.array(v1)\n",
    "    # v2 = np.array(v2)\n",
    "    \n",
    "    # calCos  內積\n",
    "\n",
    "    # dot = np.dot(v1,v2)\n",
    "    sum = 0\n",
    "    for word in commonWordSet:\n",
    "        sum = sum + ida_NL[word] * idb_NL[word]\n",
    "    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos('M.1127219109.A.837','M.1127227032.A.F3B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isUserValid(name):\n",
    "    try:\n",
    "        name_docid[name]\n",
    "        return True\n",
    "    except:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ui():\n",
    "    name = input(\"請輸入使用者ID\")\n",
    "    if isUserValid(name) == False:\n",
    "        print(\"使用者ID不合法或未在資料庫內 請重新輸入\")\n",
    "        return 0\n",
    "    else:\n",
    "        return name\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "docIDs = docID_name_NLvector.keys()\n",
    "taskmap = {}\n",
    "# map<taskNumber, [docId,Pttdocid]> \n",
    "# results<pttdocID,list[result]>\n",
    "\n",
    "\n",
    "# map<int,docid>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#開啟多個執行緒，同時執行任務，有幾個執行緒就執行幾個任務\n",
    "import threading\n",
    "import time\n",
    "import queue\n",
    "\n",
    "class MyThread(threading.Thread):\n",
    "    def __init__(self, func):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.func = func\n",
    "    def run(self):\n",
    "        self.func()\n",
    "\n",
    "\n",
    "def worker():\n",
    "    while not q.empty():\n",
    "        item = q.get()  # 或得任務\n",
    "        print('Processing : ',item)\n",
    "        doc , pttdoc = taskmap[item]\n",
    "        # 如果是自己的文章比自己的文章\n",
    "        if doc == pttdoc:\n",
    "            continue\n",
    "        try:\n",
    "            if type(results[pttdoc]) is list:\n",
    "                results[pttdoc].append(cos(doc,pttdoc))\n",
    "            else:\n",
    "                results[ pttdocdict[pttdocnum] ] = []\n",
    "                results[ pttdocdict[pttdocnum] ].append(cos(doc,pttdoc))\n",
    "        except:\n",
    "            print('!!!error ' + doc + '  '+ pttdoc)\n",
    "\n",
    "\n",
    "\n",
    "def main(name):\n",
    "    threads = []\n",
    "    targetDoclist = name_docid[name]\n",
    "    # 產生task list\n",
    "    counter = 0\n",
    "    for doc in targetDoclist:\n",
    "        for pttdoc in docIDs:\n",
    "            taskmap[counter] = []\n",
    "            taskmap[counter].append(doc)\n",
    "            taskmap[counter].append(pttdoc)\n",
    "            q.put(counter)\n",
    "            counter = counter + 1\n",
    "        print( q.qsize() ) \n",
    "\n",
    "    for i in range(threadNum):   #開啟n個執行緒\n",
    "        thread = MyThread(worker)\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = queue.Queue()\n",
    "    threadNum = 24\n",
    "    \n",
    "    # name = ui()\n",
    "    name = 'Kay731'\n",
    "    if name == 0:\n",
    "        print(\"retry\")\n",
    "    else:\n",
    "        main(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos('M.1353503637.A.14B','M.1173516369.A.2C4')\n",
    "cos('M.1353503637.A.14B','M.1173625796.A.F2A')\n",
    "cos('M.1353503637.A.14B','M.1173629372.A.C93')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tfidf['M.1353503637.A.14B']\n",
    "# docID_name['M.1353503637.A.14B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def testf():\n",
    "    for i in range(0,550000000):\n",
    "        if (i%1000000) ==0:\n",
    "            print(i)\n",
    "\n",
    "testf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}